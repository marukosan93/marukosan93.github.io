<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Research</title>
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
    <!--<meta content="some keywords?" name="keywords">-->
    <meta content="EmotionAI project website" name="description">

    <!-- Google Font -->
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300;400;600;700;800&display=swap" rel="stylesheet">

    <!-- CSS Libs -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.10.0/css/all.min.css" rel="stylesheet">
    <link href="lib/animate/animate.min.css" rel="stylesheet">

    <!-- Main stylesheet -->
    <link href="css/style.css" rel="stylesheet">

  </head>
  <body>
    <div class="flex-wrapper">
    <!-- Maybe a topbar? But doesn't seem that useful...-->

    <!-- Navbar Start -->
  <div class="navbar navbar-expand-lg bg-dark navbar-dark">
      <div class="container-fluid">
          <a href="index.html" class="navbar-brand">Emotion<span>AI</span></a>
          <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbarCollapse">
              <span class="navbar-toggler-icon"></span>
          </button>

          <div class="collapse navbar-collapse justify-content-between" id="navbarCollapse">
              <div class="navbar-nav ml-auto">
                  <a href="index.html" class="nav-item nav-link">Home</a>
                  <a href="research.html" class="nav-item nav-link active">Research</a>
                  <a href="team.html" class="nav-item nav-link">Team</a>
                  <a href="news.html" class="nav-item nav-link">News</a>
                  <a href="contact.html" class="nav-item nav-link">Contact</a>
              </div>
          </div>
      </div>
  </div>
  <!-- Nav Bar End -->

  <!-- Page Header Start -->
  <div class="empty-page-header">

  </div>
  <!-- Page Header End -->

  <!-- About Start -->
  <div class="about wow fadeInUp" data-wow-delay="0.1s">
      <div class="container-fluid">
          <div class="row align-items-center">
              <div class="col-lg-5 col-md-6">
                  <div class="about-img wow fadeInUp" data-wow-delay="0.2s">
                      <img src="img/intro.png" alt="Image">
                  </div>
              </div>
              <div class="col-lg-7 col-md-6">
                  <div class="section-header text-left wow zoomIn" data-wow-delay="0.4s">
                      <p>Current project</p>
                      <h4>Academy professor project (2021.09-2026.08): <br> Towards vision-based emotion AI (Emotion AI)</h4>

                  </div>
                  <div class="about-text wow fadeInUp" data-wow-delay="0.6s">
                      <p>
                        The Emotion AI project aims to deeply investigate novel computer vision and machine learning methodology to study how artificial intelligence (AI) can identify human emotions and bring emotion AI to human-computer interaction and computer mediated human-human interaction for boosting remote communication and collaboration. In addition to expressed visual cues, AI technology is expected to identify suppressed and unseen emotional signals, and at the same time mask people’s identity information for protecting privacy. We will work with worldwide leading experts from different disciplines, e.g., psychology, cognition sciences, education, and medicine, as well as industry, to advance the emotional intelligence of AI-based solutions and improve understanding of the significance of emotions in the context of human-computer interactions. The research knowledge generated can accelerate innovations for e.g., real-world e-teaching, e-service, health and security applications. <br> Links...
                      </p>
                      <div class="generic-btn">
                          <a class="btn wow fadeInUp" data-wow-delay="0.8s" href="research.html#demo">View Demo</a>
                          <a class="btn wow fadeInUp" data-wow-delay="1s" href="research.html#other">Other Projects</a>
                          <a class="btn wow fadeInUp" data-wow-delay="1.2s" href="research.html#publications">Publications</a>
                          <a class="btn wow fadeInUp" data-wow-delay="1.4s" href="research.html#data">Data and Code</a>
                      </div>

                  </div>
              </div>
          </div>
      </div>
  </div>
  <!-- About End -->

  <!-- wp Start -->
  <div class="wp">
      <div class="container-fluid">
          <div class="section-header text-center wow zoomIn" data-wow-delay="0.1s">
              <p>How EmotionAI is organised</p>
              <h2>Work packages</h2>
          </div>
          <div class="row">
              <div class="col-lg-4 col-md-6 wow fadeInUp" data-wow-delay="0.0s">
                  <div class="wp-item">
                      <div class="wp-icon">
                           <img src="img/pic_icon.png">
                      </div>
                      <h3>WP1</h3>
                      <p>
                          Lorem ipsum dolor sit amet elit. Phasellus nec pretium mi. Curabitur facilisis ornare velit non
                      </p>
                  </div>
              </div>
              <div class="col-lg-4 col-md-6 wow fadeInUp" data-wow-delay="0.2s">
                  <div class="wp-item">
                      <div class="wp-icon">
                          <img src="img/pic_icon.png">
                      </div>
                      <h3>WP2</h3>
                      <p>
                          Lorem ipsum dolor sit amet elit. Phasellus nec pretium mi. Curabitur facilisis ornare velit non
                      </p>
                  </div>
              </div>
              <div class="col-lg-4 col-md-6 wow fadeInUp" data-wow-delay="0.4s">
                  <div class="wp-item">
                      <div class="wp-icon">
                          <img src="img/pic_icon.png">
                      </div>
                      <h3>WP3</h3>
                      <p>
                          Lorem ipsum dolor sit amet elit. Phasellus nec pretium mi. Curabitur facilisis ornare velit non
                      </p>
                  </div>
              </div>
              <div class="col-lg-4 col-md-6 wow fadeInUp" data-wow-delay="0.6s">
                  <div class="wp-item">
                      <div class="wp-icon">
                        <img src="img/pic_icon.png">
                      </div>
                      <h3>WP4</h3>
                      <p>
                          Lorem ipsum dolor sit amet elit. Phasellus nec pretium mi. Curabitur facilisis ornare velit non
                      </p>
                  </div>
              </div>
              <div class="col-lg-4 col-md-6 wow fadeInUp" data-wow-delay="0.8s">
                  <div class="wp-item">
                      <div class="wp-icon">
                        <img src="img/pic_icon.png">
                      </div>
                      <h3>WP5</h3>
                      <p>
                          Lorem ipsum dolor sit amet elit. Phasellus nec pretium mi. Curabitur facilisis ornare velit non
                      </p>
                  </div>
              </div>
              <div class="col-lg-4 col-md-6 wow fadeInUp" data-wow-delay="1s">
                  <div class="wp-item">
                      <div class="wp-icon">
                        <img src="img/pic_icon.png">
                      </div>
                      <h3>WP6</h3>
                      <p>
                          Lorem ipsum dolor sit amet elit. Phasellus nec pretium mi. Curabitur facilisis ornare velit non
                      </p>
                  </div>
              </div>
          </div>
      </div>
  </div>
  <!-- wp End -->

  <!-- publications start -->
  <div class="publications wow fadeInUp" data-wow-delay="0.1s">
      <div class="container-fluid" id="publications">
        <div class="section-header text-center wow zoomIn" data-wow-delay="0.3s">
            <p> Project </p>
            <h4>Publications</h4>
        </div>

        <p class="wow fadeInUp" data-wow-delay="0.4s">You can also find all the other publications from our team by clicking <a href="https://gyzhao-nm.github.io/Guoying/">here</a> and/or <a href="https://www.oulu.fi/university/researcher/guoying-zhao">here</a></p>

        <table class="table  table-hover wow fadeInUp" data-wow-delay="0.4s">
      <thead>
        <tr>
          <th class="w-75" scope="col">Article</th>
          <th class="w-25 text-right align-self-center" scope="col">Year</th>
        </tr>
      </thead>
      <tbody>
        <!-- paper -->
        <tr class="wow fadeInUp"  data-wow-delay="0.5s">
          <td class="w-75" >
             <a href="https://www.w3schools.com">Paper</a>
            <p>Authors</p>
            <p>Journal</p>
          </td>
          <th class="w-25 text-right"  scope="row">2021</th>
        </tr>
        <!-- paper -->
        <tr class="wow fadeInUp"  data-wow-delay="0.6s">
          <td class="w-75" >
             <a href="https://www.w3schools.com">Paper</a>
            <p>Authors</p>
            <p>Journal</p>
          </td>
          <th class="w-25 text-right"  scope="row">2021</th>
        </tr>
        <!-- paper -->
        <tr class="wow fadeInUp"  data-wow-delay="0.7s">
          <td class="w-75" >
             <a href="https://www.w3schools.com">Paper</a>
            <p>Authors</p>
            <p>Journal</p>
          </td>
          <th class="w-25 text-right"  scope="row">2021</th>
        </tr>


        <!-- Newer papers should be on top -->

      </tbody>
    </table>

    </div>

      </div>
    </div>

  <!-- publications end -->

  <!-- Other  start-->
  <div class="other wow fadeInUp" data-wow-delay="0.1s">
      <div class="container-fluid" id="other">
        <div class="section-header text-center wow zoomIn" data-wow-delay="0.2s">
            <p> Other</p>
            <h4>Projects</h4>
        </div>
        <p class="wow fadeInUp" data-wow-delay="0.4s">There are several other projects we are working on, such as:</p>
        <div class="row justify-content-center">
          <div class="col-xxl-6 col-xl-6 col-lg-6 col-md-12  col-sm-12  wow fadeInUp" data-wow-delay="0.4s">
              <div class="other-item">
                  <h3>MiGA project</h3>
                  <p>Academy project (2018.09-2022.08): Micro-gesture analysis with machine learning for hidden emotion understanding (MiGA)
MiGA project aims to understand human hidden emotions via body gestures. Micro-gestures are inconspicuous, spontaneous gestures, most of which are beyond our awareness, or unconscious. Being able to automatically detect and then amplify such gestures so that enables one to discover their symbolic meaning, opening up rich paths of emotional intelligence. In this project, we introduced a new dataset for the emotional artificial intelligence research: identity-free video dataset for Micro Gesture Understanding and Emotion analysis (iMiGUE), which contains 359 short-length videos of 72 famous tennis players. This project is proposed for purely research purposes to enhance the algorithms of recognition of micro-gestures and emotions.<br> Links...
                  </p>
              </div>
          </div>
          <div class="col-xxl-6 col-xl-6 col-lg-6 col-md-12  col-sm-12  wow fadeInUp" data-wow-delay="0.6s">

          <div class="column justify-content-center">
            <div class="row-xxl-6 row-xl-6 row-lg-6 row-md-12  row-sm-12  wow fadeInUp" data-wow-delay="0.8s">
                <div class="other-item">
                    <h3>Academy ICT project</h3>
                    <p>
Academy ICT 2023 project (2020.01-2022.12): Context-aware autonomous neural network learning <br> Links...
                    </p>
                </div>
            </div>

            <div class="row-xxl-6 row-xl-6 row-lg-6 row-md-12  row-sm-12  wow fadeInUp" data-wow-delay="1.0s">
                <div class="other-item">
                    <h3>Spearhead project</h3>
                    <p>
Spearhead project (2018.09-2022.08): Towards Reading Micro-Expressions in the Real World

  <br>Links...
                    </p>
                </div>
            </div>
          </div>
        </div>

  </div>





  <!-- Data  start-->
  <div class="data wow fadeInUp" data-wow-delay="0.1s">
      <div class="container-fluid" id="data">
        <div class="section-header text-center wow zoomIn" data-wow-delay="0.2s">
            <p> Sharing</p>
            <h4>Datasets and code</h4>
        </div>
        <p class="wow fadeInUp" data-wow-delay="0.4s">Not sure what we are going to share. Just one project github page, several??? For now I'm leaving it like this. <br> You can find some of our code on <a href="https://github.com/CV-AC">https://github.com/CV-AC</a></p>
        <p class="wow fadeInUp" data-wow-delay="0.6s">There are several datasets we share with the research community, all of them are listed below. If you are interested, please contact us.</p>
        <div class="row justify-content-center">
            <div class="col-xxl-4 col-xl-6 col-lg-6 col-md-12  col-sm-12  wow fadeInUp" data-wow-delay="0.8s">
              <div class="data-item">
                  <h3>OuluVS database</h3>
                  <p>
                    Oulu VS database includes the video and audio data for 20 subjects uttering ten phrases: Hello, Excuse me, I am sorry, Thank you, Good bye, See you, Nice to meet you, You are welcome, How are you, Have a good time. Each person spoke each phrase five times. There are also videos with head motion from front to left, from front to right, without utterance, five times for each person. The database can be used, for example, in studying the visual speech recognition (lipreading).
                    <br>
                    <br>
The details and the baseline results for visual speech recognition can be found in:
<a href="https://ieeexplore.ieee.org/document/5208233">Zhao G, Barnard M & Pietikäinen M (2009). Lipreading with local spatiotemporal descriptors. IEEE Transactions on Multimedia 11(7):1254-1265</a>
                  </p>
              </div>
            </div>
            <div class="col-xxl-4 col-xl-6 col-lg-6 col-md-12  col-sm-12   wow fadeInUp" data-wow-delay="1.0s">
              <div class="data-item">
                  <h3>Oulu-CASIA NIR&VIS facial expression database</h3>
                  <p>
                    Oulu-CASIA NIR&VIS facial expression database contains videos with the six typical expressions  (happiness, sadness, surprise,anger, fear, disgust) from 80 subjects captured with two imaging systems, NIR (Near Infrared) and VIS (Visible light), under three different illumination conditions: normal indoor illumination, weak illumination (only computer display is on) and dark illumination (all lights are off). The database can be used, for example,  in studying the effects of illumination variations to facial expressions, cross-imaging-system facial expression recognition or face recognition.
                    <br>
                    <br>
The details and the baseline results for visual speech recognition can be found in:
<a href="https://ieeexplore.ieee.org/abstract/document/4761697">Zhao, G., Huang, X., Taini, M., Li, S. Z., & PietikäInen, M. (2011). Facial expression recognition from near-infrared videos. Image and Vision Computing, 29(9), 607-619.</a>
                  </p>
              </div>
            </div>
            <div class="col-xxl-4 col-xl-6 col-lg-6 col-md-12  col-sm-12  wow fadeInUp" data-wow-delay="1.2s">
                <div class="data-item">
                    <h3>SPOS database - spontaneous and posed facial expressions database</h3>
                    <p>
                      SPOS database includes spontaneous and posed facial expressions of 7 subjects. Emotional movie clips were shown to subjects to induce spontaneous facial expressions, which include six categories of basic emotions (happy, sad, anger, surprise, fear disgust). Subjects were also asked to pose the six kinds of facial expressions after watching movie clips. Data are recorded by both visual and near infer-red camera. All together 84 posed and 147 spontaneous facial expression clips were labeled out from the starting point to the apex.
                      <br>
                      So far, spontaneous and posed facial expressions are usually found in different databases. The difference between databases (different experimental setting and different participants) hindered researches which considered both spontaneous and posed facial expressions. This database offers data collected on the same participants and under the same recording condition, which can be used for comparing or distinguishing spontaneous and posed facial expressions
                      <br>
                      <br>
  The details and the baseline results for visual speech recognition can be found in:
  <a href="https://ieeexplore.ieee.org/abstract/document/6126401">Pfister, T.; Xiaobai Li; Guoying Zhao; Pietikainen, M., "Recognising spontaneous facial micro-expressions," in Computer Vision (ICCV), 2011 IEEE International Conference on , vol., no., pp.1449-1456, 6-13 Nov. 2011</a>
                    </p>
                </div>
            </div>

  </div>

  <!-- Demo start -->
  <div class="demo wow fadeInUp" data-wow-delay="0.1s">
      <div class="container-fluid" id="demo">
        <div class="section-header text-center wow zoomIn" data-wow-delay="0.2s">
            <p>Some applications</p>
            <h4>Demos</h4>
        </div>
        <p class="wow fadeInUp" data-wow-delay="0.4s">Coming soon</p>
        <div class="video wow fadeInUp" data-wow-delay="0.6s">
        <iframe width="420" height="345" src="https://www.youtube.com/embed/WStoojF1VHA"></iframe>
      </div>
      </div>
  </div>
  <!-- Demo end -->

  <!-- Footer -->
</div>
  <footer class="page-footer font-small black  wow fadeInUp" data-wow-delay="0.2s">
    <!-- Copyright -->
    <div class="footer-copyright text-center py-3">
      <p class="foot-text">© 2021 Copyright</p>
    </div>
    <!-- Copyright -->

  </footer>
  <!-- Footer -->


  <!-- JavaScript Libs -->
  <script src="https://code.jquery.com/jquery-3.4.1.min.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.bundle.min.js"></script>
  <script src="lib/wow/wow.min.js"></script>

  <!-- Main Javascript -->
  <script src="js/main.js"></script>
  </body>
</html>
